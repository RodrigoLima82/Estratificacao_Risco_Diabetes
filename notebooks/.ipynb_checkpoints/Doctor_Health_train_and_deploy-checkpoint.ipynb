{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category-encoders\n",
      "  Downloading category_encoders-2.2.2-py2.py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 1.3 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /Users/rodrigolima82/opt/anaconda3/lib/python3.8/site-packages (from category-encoders) (1.18.5)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /Users/rodrigolima82/opt/anaconda3/lib/python3.8/site-packages (from category-encoders) (0.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/rodrigolima82/opt/anaconda3/lib/python3.8/site-packages (from category-encoders) (0.23.1)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /Users/rodrigolima82/opt/anaconda3/lib/python3.8/site-packages (from category-encoders) (1.0.5)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /Users/rodrigolima82/opt/anaconda3/lib/python3.8/site-packages (from category-encoders) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/rodrigolima82/opt/anaconda3/lib/python3.8/site-packages (from category-encoders) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/rodrigolima82/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->category-encoders) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/rodrigolima82/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->category-encoders) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/rodrigolima82/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.21.1->category-encoders) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/rodrigolima82/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.21.1->category-encoders) (2020.1)\n",
      "Requirement already satisfied: six in /Users/rodrigolima82/opt/anaconda3/lib/python3.8/site-packages (from patsy>=0.5.1->category-encoders) (1.15.0)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install category-encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import category_encoders as ce \n",
    "\n",
    "# Cria o padronizador\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(dados):\n",
    "\n",
    "    # Removendo as 3 colunas com alto percentual de valores ausentes\n",
    "    dados = dados.drop(['weight','payer_code','medical_specialty'], axis = 1)\n",
    "\n",
    "    # Removemos os registros com baixo percentual de valores ausentes\n",
    "    dados = dados[dados['race'] != '?']\n",
    "    dados = dados[dados['diag_1'] != '?']\n",
    "    dados = dados[dados['diag_2'] != '?']\n",
    "    dados = dados[dados['diag_3'] != '?']\n",
    "    dados = dados[dados['gender'] != 'Unknown/Invalid']\n",
    "\n",
    "    # Removendoo variáveis com valores únicos\n",
    "    dados = dados.loc[:, dados.nunique() != 1]\n",
    "\n",
    "    # Ajustando a variável alvo\n",
    "    # '0' significa que não foi readmitido\n",
    "    # '1' significa que foi readmitido, não importa quantos dias após a alta\n",
    "    dados['readmitted'] = dados['readmitted'].replace('>30', 1)\n",
    "    dados['readmitted'] = dados['readmitted'].replace('<30', 1)\n",
    "    dados['readmitted'] = dados['readmitted'].replace('NO', 0)\n",
    "\n",
    "    # Recategorizamos 'idade' para que a população seja distribuída de maneira mais uniforme\n",
    "    # Classificamos como faixa de 0-50 pacientes de até 50 anos\n",
    "    dados['age'] = pd.Series(['[0-50)' if val in ['[0-10)', '[10-20)', '[20-30)', '[30-40)', '[40-50)'] else val \n",
    "                              for val in dados['age']], index = dados.index)\n",
    "\n",
    "    # Acima de 80 anos ficam na faixa de 80-100\n",
    "    dados['age'] = pd.Series(['[80-100)' if val in ['[80-90)', '[90-100)'] else val \n",
    "                              for val in dados['age']], index = dados.index)\n",
    "\n",
    "\n",
    "    # A variável 'admission_type_id' contém 8 níveis\n",
    "    # Reduziremos os níveis de 'admission_type_id' para duas categorias\n",
    "    dados['admission_type_id'] = pd.Series(['Emergencia' if val == 1 else 'Outro' \n",
    "                                            for val in dados['admission_type_id']], index = dados.index)\n",
    "\n",
    "\n",
    "    # A variável 'discharge_disposition_id' contém 26 níveis\n",
    "    # Reduziremos os níveis de 'discharge_disposition_id' para duas categorias\n",
    "    dados['discharge_disposition_id'] = pd.Series(['Casa' if val == 1 else 'Outro' \n",
    "                                                  for val in dados['discharge_disposition_id']], index = dados.index)\n",
    "\n",
    "\n",
    "    # A variável 'admission_source_id' contém 17 níveis\n",
    "    # # Reduziremos os níveis de 'admission_source_id' para três categorias\n",
    "    dados['admission_source_id'] = pd.Series(['Sala_Emergencia' if val == 7 else 'Recomendacao' if val == 1 else 'Outro' \n",
    "                                                  for val in dados['admission_source_id']], index = dados.index)\n",
    "\n",
    "\n",
    "    # Concatena 3 variáveis em um dataframe\n",
    "    diagnostico = dados[['diag_1', 'diag_2', 'diag_3']]\n",
    "\n",
    "    # Aplicamos a função comorbidade aos dados\n",
    "    dados['comorbidade'] = diagnostico.apply(calcula_comorbidade, axis = 1)\n",
    "\n",
    "    # Drop das variáveis individuais\n",
    "    dados.drop(['diag_1','diag_2','diag_3'], axis = 1, inplace = True)\n",
    "    \n",
    "    # Removendo dataframe temporario\n",
    "    del diagnostico\n",
    "\n",
    "    # Lista com os nomes das variáveis de medicamentos (3 variáveis já tinham sido removidas)\n",
    "    medicamentos = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', \n",
    "                    'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', \n",
    "                    'troglitazone', 'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin', \n",
    "                    'glimepiride-pioglitazone', 'metformin-pioglitazone']\n",
    "\n",
    "\n",
    "    # Loop para ajustar o valor das variáveis de medicamentos\n",
    "    for col in medicamentos:\n",
    "        if col in dados.columns:\n",
    "            colname = str(col) + 'temp'\n",
    "            dados[colname] = dados[col].apply(lambda x: 0 if (x == 'No' or x == 'Steady') else 1)\n",
    "\n",
    "\n",
    "    # Cria uma variável para receber a contagem por paciente\n",
    "    dados['num_alt_dosagem_med'] = 0\n",
    "\n",
    "    # Contagem de modificações na dosagem de medicamentos\n",
    "    for col in medicamentos:\n",
    "        if col in dados.columns:\n",
    "            colname = str(col) + 'temp'\n",
    "            dados['num_alt_dosagem_med'] = dados['num_alt_dosagem_med'] + dados[colname]\n",
    "            del dados[colname]\n",
    "\n",
    "\n",
    "    # Recoding das colunas de medicamentos\n",
    "    for col in medicamentos:\n",
    "        if col in dados.columns:\n",
    "            dados[col] = dados[col].replace('No', 0)\n",
    "            dados[col] = dados[col].replace('Steady', 1)\n",
    "            dados[col] = dados[col].replace('Up', 1)\n",
    "            dados[col] = dados[col].replace('Down', 1) \n",
    "\n",
    "\n",
    "    # Variável com a contagem de medicamentos por paciente\n",
    "    dados['num_med'] = 0\n",
    "\n",
    "    # Carregamos a nova variável\n",
    "    for col in medicamentos:\n",
    "        if col in dados.columns:\n",
    "            dados['num_med'] = dados['num_med'] + dados[col]\n",
    "\n",
    "\n",
    "    # Remove as colunas de medicamentos\n",
    "    dados = dados.drop(columns = medicamentos)\n",
    "\n",
    "\n",
    "    # Recoding de variáveis categóricas binárias\n",
    "    dados['change'] = dados['change'].replace('Ch', 1)\n",
    "    dados['change'] = dados['change'].replace('No', 0)\n",
    "    dados['gender'] = dados['gender'].replace('Male', 1)\n",
    "    dados['gender'] = dados['gender'].replace('Female', 0)\n",
    "    dados['diabetesMed'] = dados['diabetesMed'].replace('Yes', 1)\n",
    "    dados['diabetesMed'] = dados['diabetesMed'].replace('No', 0)\n",
    "\n",
    "\n",
    "    # Recoding de variáveis categóricas (label encoding)\n",
    "    dados['A1Cresult'] = dados['A1Cresult'].replace('>7', 1)\n",
    "    dados['A1Cresult'] = dados['A1Cresult'].replace('>8', 1)\n",
    "    dados['A1Cresult'] = dados['A1Cresult'].replace('Norm', 0)\n",
    "    dados['A1Cresult'] = dados['A1Cresult'].replace('None', -99)\n",
    "    dados['max_glu_serum'] = dados['max_glu_serum'].replace('>200', 1)\n",
    "    dados['max_glu_serum'] = dados['max_glu_serum'].replace('>300', 1)\n",
    "    dados['max_glu_serum'] = dados['max_glu_serum'].replace('Norm', 0)\n",
    "    dados['max_glu_serum'] = dados['max_glu_serum'].replace('None', -99)\n",
    "\n",
    "\n",
    "    # Removendo duplicidades por id de paciente, mantendo o primeiro registro\n",
    "    dados = dados.drop_duplicates(subset = ['patient_nbr'], keep = 'first')\n",
    "\n",
    "\n",
    "    # Remove as variáveis de ID\n",
    "    dados.drop(['encounter_id', 'patient_nbr'], axis = 1, inplace = True)\n",
    "    \n",
    "    return dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que calcula a Comorbidade\n",
    "def calcula_comorbidade(row):\n",
    "    \n",
    "    # Código 250 indica diabetes\n",
    "    codigos_doenca_diabetes = \"^[2][5][0]\"\n",
    "    \n",
    "    # Códigos 39x (x = valor entre 0 e 9)\n",
    "    # Códigos 4zx (z = valor entre 0 e 6 e x = valor entre 0 e 9)\n",
    "    # Esses códigos indicam problemas circulatórios\n",
    "    codigos_doenca_circulatorios = \"^[3][9][0-9]|^[4][0-5][0-9]\"\n",
    "    \n",
    "    # Inicializa variável de retorno\n",
    "    valor = 0\n",
    "    \n",
    "    # Valor 0 indica que:\n",
    "    # Diabetes E problemas circulatórios não foram detectados de forma simultânea no paciente\n",
    "    if(not(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_1']))))) and\n",
    "       not(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_2']))))) and \n",
    "       not(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_3'])))))) and (not(\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_1']))))) and not(\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_2']))))) and not(\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_3'])))))):\n",
    "        valor = 0\n",
    "        \n",
    "    # Valor 1 indica que:\n",
    "    # Pelo menos um diagnóstico de diabetes E problemas circulatórios foram detectados de forma \n",
    "    # simultânea no paciente\n",
    "    if(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_1'])))) or \n",
    "       bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_2'])))) or \n",
    "       bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_3']))))) and (not(\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_1']))))) and not(\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_2']))))) and not(\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_3'])))))): \n",
    "        valor = 1\n",
    "        \n",
    "    # Valor 2 indica que:\n",
    "    # Diabetes E pelo menos um diagnóstico de problemas circulatórios foram detectados de forma \n",
    "    # simultânea no paciente\n",
    "    if(not(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_1']))))) and\n",
    "       not(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_2']))))) and \n",
    "       not(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_3'])))))) and (\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_1'])))) or \n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_2'])))) or \n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_3']))))):\n",
    "        valor = 2\n",
    "        \n",
    "    # Valor 3 indica que:\n",
    "    # Pelo menos um diagnóstico de diabetes e pelo menos um diagnóstico de problemas circulatórios \n",
    "    # foram detectados de forma simultânea no paciente\n",
    "    if(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_1'])))) or \n",
    "       bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_2'])))) or \n",
    "       bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_3']))))) and (\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_1'])))) or \n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_2'])))) or \n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_3']))))):\n",
    "        valor = 3 \n",
    "    \n",
    "    return valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para balanceamento entre as classes\n",
    "def balanceamento_classe(X, y):\n",
    "\n",
    "    # Criamos o objeto SMOTE\n",
    "    sm = SMOTE(random_state = 42)\n",
    "\n",
    "    # Treinamos o balanceador SMOTE\n",
    "    new_X, new_y = sm.fit_sample(X, y)   \n",
    "    \n",
    "    return new_X, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando engenharia de atributos no dataset\n",
    "train = feature_engineering(df)\n",
    "\n",
    "# Vamos armazenar 'readmitted' no rótulo (y) e o restante das colunas em X\n",
    "y = train['readmitted']\n",
    "X = train.drop(['readmitted'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_leave = ce.LeaveOneOutEncoder(cols = ['age','race','admission_type_id','discharge_disposition_id','admission_source_id'])\n",
    "ce = ce_leave.fit(X, y)        \n",
    "X = ce.transform(X, y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>...</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>max_glu_serum</th>\n",
       "      <th>A1Cresult</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>comorbidade</th>\n",
       "      <th>num_alt_dosagem_med</th>\n",
       "      <th>num_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.412180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350787</td>\n",
       "      <td>0.407403</td>\n",
       "      <td>0.394089</td>\n",
       "      <td>0.426748</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.387634</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350882</td>\n",
       "      <td>0.407432</td>\n",
       "      <td>0.394113</td>\n",
       "      <td>0.426775</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.412199</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350882</td>\n",
       "      <td>0.407432</td>\n",
       "      <td>0.394113</td>\n",
       "      <td>0.426775</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.412199</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350882</td>\n",
       "      <td>0.407432</td>\n",
       "      <td>0.394113</td>\n",
       "      <td>0.426775</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.412180</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375313</td>\n",
       "      <td>0.401110</td>\n",
       "      <td>0.394089</td>\n",
       "      <td>0.366485</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       race  gender       age  admission_type_id  discharge_disposition_id  \\\n",
       "1  0.412180       0  0.350787           0.407403                  0.394089   \n",
       "2  0.387634       0  0.350882           0.407432                  0.394113   \n",
       "3  0.412199       1  0.350882           0.407432                  0.394113   \n",
       "4  0.412199       1  0.350882           0.407432                  0.394113   \n",
       "5  0.412180       1  0.375313           0.401110                  0.394089   \n",
       "\n",
       "   admission_source_id  time_in_hospital  num_lab_procedures  num_procedures  \\\n",
       "1             0.426748                 3                  59               0   \n",
       "2             0.426775                 2                  11               5   \n",
       "3             0.426775                 2                  44               1   \n",
       "4             0.426775                 1                  51               0   \n",
       "5             0.366485                 3                  31               6   \n",
       "\n",
       "   num_medications  ...  number_emergency  number_inpatient  number_diagnoses  \\\n",
       "1               18  ...                 0                 0                 9   \n",
       "2               13  ...                 0                 1                 6   \n",
       "3               16  ...                 0                 0                 7   \n",
       "4                8  ...                 0                 0                 5   \n",
       "5               16  ...                 0                 0                 9   \n",
       "\n",
       "   max_glu_serum  A1Cresult  change  diabetesMed  comorbidade  \\\n",
       "1            -99        -99       1            1            1   \n",
       "2            -99        -99       0            1            1   \n",
       "3            -99        -99       1            1            3   \n",
       "4            -99        -99       1            1            1   \n",
       "5            -99        -99       0            1            3   \n",
       "\n",
       "   num_alt_dosagem_med  num_med  \n",
       "1                    1        1  \n",
       "2                    0        1  \n",
       "3                    1        1  \n",
       "4                    0        2  \n",
       "5                    0        1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dos dados\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=0, stratify=y)\n",
    "\n",
    "# Padronizando os dados\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val   = scaler.transform(X_val)\n",
    "\n",
    "# Aplicar o balanceamento de classes usando SMOTE\n",
    "X_train, y_train = balanceamento_classe(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurácia do Modelo de Regressão Logística (%): 57.89013550925252\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Não       0.67      0.57      0.62      8176\n",
      "         Sim       0.48      0.60      0.53      5550\n",
      "\n",
      "    accuracy                           0.58     13726\n",
      "   macro avg       0.58      0.58      0.58     13726\n",
      "weighted avg       0.60      0.58      0.58     13726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cria o modelo\n",
    "modelo_lr = LogisticRegression(tol = 1e-7, \n",
    "                               class_weight = {0:0.49, 1:0.51}, \n",
    "                               penalty = 'l2', \n",
    "                               C = 0.0005, \n",
    "                               solver = 'liblinear')\n",
    "\n",
    "# Treina o modelo\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "\n",
    "# Faz as previsões\n",
    "lr_pred = modelo_lr.predict(X_val)\n",
    "\n",
    "# Calcula o score com dados de teste\n",
    "lr_accuracy = modelo_lr.score(X_val, y_val) * 100\n",
    "\n",
    "# Print\n",
    "print(\"\\nAcurácia do Modelo de Regressão Logística (%):\", lr_accuracy)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Relatório de Classificação\n",
    "print(classification_report(y_val, lr_pred, target_names = ['Não', 'Sim']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/ce_leave.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(modelo_lr, '../models/modelo_lr.pkl')\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "joblib.dump(ce, '../models/ce_leave.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install azureml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install azureml-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install azureml-dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config(path=\"../config/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "np.savetxt('features.csv', X, delimiter=',')\n",
    "np.savetxt('labels.csv', y, delimiter=',')\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload_files(files=['./features.csv', './labels.csv'],\n",
    "                       target_path='sklearn_classification/',\n",
    "                       overwrite=True)\n",
    "\n",
    "input_dataset = Dataset.Tabular.from_delimited_files(path=[(datastore, 'sklearn_classification/features.csv')])\n",
    "output_dataset = Dataset.Tabular.from_delimited_files(path=[(datastore, 'sklearn_classification/labels.csv')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_name='doctorhealth-model',              # Name of the registered model in your workspace.\n",
    "                       model_path='../models/modelo_lr.pkl',         # Local file to upload and register as a model.\n",
    "                       model_framework=Model.Framework.SCIKITLEARN,  # Framework used to create the model.\n",
    "                       model_framework_version=sklearn.__version__,  # Version of scikit-learn used to create the model.\n",
    "                       sample_input_dataset=input_dataset,\n",
    "                       sample_output_dataset=output_dataset,\n",
    "                       resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=0.5),\n",
    "                       description='Logistic Regression model to predict readmitted risk diabetes.',\n",
    "                       tags={'area': 'diabetes', 'type': 'classification'})\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name = 'doctorhealth-service'\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], overwrite=True)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = X.iloc[:1, 0:]\n",
    "sample_json = sample.to_json(orient=\"split\")\n",
    "query_input = list(sample.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def query_endpoint_example(scoring_uri, inputs, service_key=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    if service_key is not None:\n",
    "        headers[\"Authorization\"] = \"Bearer {service_key}\".format(service_key=service_key)\n",
    "\n",
    "    print(\"Sending batch prediction request with inputs: {}\".format(inputs))\n",
    "    response = requests.post(scoring_uri, data=inputs, headers=headers)\n",
    "    print(\"Response: {}\".format(response.text))\n",
    "    preds = json.loads(response.text)\n",
    "    print(\"Received response: {}\".format(preds))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_scoring_uri = service.scoring_uri\n",
    "print(aci_scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = query_endpoint_example(scoring_uri=aci_scoring_uri, inputs=sample_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy web service to AKS\n",
    "> Observacao: na conta Free da Azure nao foi possivel por conta da QuotaExceeded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.model import Model\n",
    "import azureml.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "conda_deps = CondaDependencies.create(conda_packages=['numpy','scikit-learn==0.23.2','scipy'], pip_packages=['azureml-defaults', 'inference-schema'])\n",
    "myenv = Environment(name='doctorhealth_env')\n",
    "myenv.python.conda_dependencies = conda_deps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the Entry Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
    "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
    "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
    "    model_path = os.path.join(os.getenv('../models/'), 'modelo_lr.pkl')\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# note you can pass in multiple rows for scoring\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data']\n",
    "        data = numpy.array(data)\n",
    "        result = model.predict(data)\n",
    "        # you can return any data type as long as it is JSON-serializable\n",
    "        return result.tolist()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the InferenceConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inf_config = InferenceConfig(entry_script='score.py', environment=myenv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provision the AKS Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your AKS cluster\n",
    "aks_name = 'aksdoctorhealth' \n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # Use the default configuration (can also provide parameters to customize)\n",
    "    prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "    # Create the cluster\n",
    "    aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                      name = aks_name, \n",
    "                                      provisioning_configuration = prov_config)\n",
    "\n",
    "if aks_target.get_status() != \"Succeeded\":\n",
    "    aks_target.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
