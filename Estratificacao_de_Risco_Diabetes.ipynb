{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estratificando riscos usando registros eletrônicos de pacientes diabéticos\n",
    "\n",
    "Autor: Rodrigo de Lima Oliveira\n",
    "\n",
    "Referências:\n",
    "\n",
    "[DSA] https://www.datascienceacademy.com.br/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as m\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scikitplot.metrics import plot_confusion_matrix, plot_roc\n",
    "\n",
    "# Imports para formatação dos gráficos\n",
    "plt.style.use('fivethirtyeight')\n",
    "m.rcParams['axes.labelsize'] = 14\n",
    "m.rcParams['xtick.labelsize'] = 12\n",
    "m.rcParams['ytick.labelsize'] = 12\n",
    "m.rcParams['text.color'] = 'k'\n",
    "from matplotlib.pylab import rcParams \n",
    "rcParams['figure.figsize'] = 14,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados\n",
    "df = pd.read_csv(\"data/diabetes.csv\")\n",
    "\n",
    "# Exibindo primeiros registros do dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicionário de Dados:\n",
    "- 0- **encounter_id** - identificador único de um encontro do pesquisador com o paciente.\n",
    "- 1- **patient_nbr** - identificador exclusivo de um paciente.\n",
    "- 2- **race** - valores: Caucasian, Asian, African American, Hispanic e other.\n",
    "- 3- **gender** - valores: male, female, and unknown/invalid.\n",
    "- 4- **age** - agrupados em intervalos de 10 anos: (0, 10), (10, 20), ..., (90, 100).\n",
    "- 5- **weight** - peso em libras.\n",
    "- 6- **admission_type_id** - identificador inteiro correspondente a 9 valores distintos, por exemplo, \"emergência, urgência, eletiva, recém-nascido e não disponível\".\n",
    "- 7- **discharge_disposition_id** - identificador inteiro correspondente a 29 valores distintos, por exemplo, \"enviado para casa, expirou e não está disponível\".\n",
    "- 8- **admission_source_id** - identificador inteiro correspondente a 21 valores distintos, por exemplo, \"encaminhamento médico, e transferência de um hospital\".\n",
    "- 9- **time_in_hospital** - número inteiro de dias entre a admissão e a alta,\n",
    "- 10- **payer_code** - identificador inteiro correspondente a 23 valores distintos, por exemplo, Blue Cross / Blue Shield, Medicare e auto-pagamento\".\n",
    "- 11- **medical_specialty** - identificador inteiro de uma especialidade do médico admitidor, correspondente a 84 valores distintos, por exemplo, cardiologia, medicina interna, família / clínica geral e cirurgião\".\n",
    "- 12- **num_lab_procedures** - número de testes de laboratório realizados durante a consulta.\n",
    "- 13- **num_procedures** - número de procedimentos (exceto testes de laboratório) realizados durante a consulta.\n",
    "- 14- **num_medications** - número de medicamentos genéricos distintos administrados durante a consulta.\n",
    "- 15- **number_outpatient** - número de consultas ambulatoriais do paciente no ano anterior a consulta.\n",
    "- 16- **number_emergency** - número de visitas de emergência do paciente no ano anterior a consulta.\n",
    "- 17- **number_inpatient** - número de visitas hospitalares do paciente no ano anterior a consulta.\n",
    "- 18- **diag_1** - diagnóstico primário (codificado como três primeiros dígitos da CID9); 848 valores distintos.\n",
    "- 19- **diag_2** - diagnóstico secundário (codificado como três primeiros dígitos da CID9); 923 valores distintos.\n",
    "- 20- **diag_3** - diagnóstico secundário adicional (codificado como três primeiros dígitos da CID9); 954 valores distintos.\n",
    "- 21- **number_diagnoses** - número de diagnósticos inseridos no sistema.\n",
    "- 22- **max_glu_serum** - teste sérico de glicose que indica a faixa do resultado ou se o teste não foi realizado. Valores: > 200, > 300, normal e nenhum, se não for medido.\n",
    "- 23- **A1Cresult** - teste A1c que indica o intervalo do resultado ou se o teste não foi realizado. Valores: > 8 (se o resultado for maior que 8%), > 7 (se o resultado for maior que 7%, porém menor que 8%), normal (se o resultado for inferior a 7%) e nenhum, se não for medido.\n",
    "\n",
    "Na sequência temos os recursos de 24 a 46 para os nomes dos medicamentos genéricos:\n",
    "\n",
    "metformina, repaglinida, nateglinida, clorpropamida, glimepirida, acetohexamida, glipizida, gliburida, tolbutamida, pioglitazona, rosiglitazona, acarbose, miglitol, troglitazona, insulazforamida, examide, sitaglagliptida, sitazagliptida , glipizida-metformina, glimepirida-pioglitazona, metformina-rosiglitazona e metformina-pioglitazona, \n",
    "\n",
    "Cada um desses recursos indica se o medicamento foi prescrito ou se houve uma alteração na dosagem. Valores: \"up\" se a dose foi aumentada durante a consulta. \n",
    "\n",
    "- 47- **change** - indica se houve alteração nos medicamentos para diabéticos (dosagem ou nome genérico). Valores: \"change\" e \"no change\".\n",
    "- 48- **diabetesMed** - indica se houve algum medicamento diabético prescrito. Valores: \"sim\" e \"não\".\n",
    "- 49- **readmitted** - readmitido, \"Dias para readmissão hospitalar. Valores: <30 (se o paciente foi readmitido em menos de 30 dias), > 30 (se o paciente foi readmitido em mais de 30 dias) e No, para nenhum registro de readmissão. \n",
    "\n",
    "Nota: Códigos ICD-9 ou CID-9 (International Classification of Diseases ou Código Internacional de Doenças)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando Engenharia de Atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(dados):\n",
    "\n",
    "    # Removendo as 3 colunas com alto percentual de valores ausentes\n",
    "    dados = dados.drop(['weight','payer_code','medical_specialty'], axis = 1)\n",
    "\n",
    "    # Removemos os registros com baixo percentual de valores ausentes\n",
    "    dados = dados[dados['race'] != '?']\n",
    "    dados = dados[dados['diag_1'] != '?']\n",
    "    dados = dados[dados['diag_2'] != '?']\n",
    "    dados = dados[dados['diag_3'] != '?']\n",
    "    dados = dados[dados['gender'] != 'Unknown/Invalid']\n",
    "\n",
    "    # Removendoo variáveis com valores únicos\n",
    "    dados = dados.loc[:, dados.nunique() != 1]\n",
    "\n",
    "    # Ajustando a variável alvo\n",
    "    # '0' significa que não foi readmitido\n",
    "    # '1' significa que foi readmitido, não importa quantos dias após a alta\n",
    "    dados['readmitted'] = dados['readmitted'].replace('>30', 1)\n",
    "    dados['readmitted'] = dados['readmitted'].replace('<30', 1)\n",
    "    dados['readmitted'] = dados['readmitted'].replace('NO', 0)\n",
    "\n",
    "    # Recategorizamos 'idade' para que a população seja distribuída de maneira mais uniforme\n",
    "    # Classificamos como faixa de 0-50 pacientes de até 50 anos\n",
    "    dados['age'] = pd.Series(['[0-50)' if val in ['[0-10)', '[10-20)', '[20-30)', '[30-40)', '[40-50)'] else val \n",
    "                              for val in dados['age']], index = dados.index)\n",
    "\n",
    "    # Acima de 80 anos ficam na faixa de 80-100\n",
    "    dados['age'] = pd.Series(['[80-100)' if val in ['[80-90)', '[90-100)'] else val \n",
    "                              for val in dados['age']], index = dados.index)\n",
    "\n",
    "\n",
    "    # A variável 'admission_type_id' contém 8 níveis\n",
    "    # Reduziremos os níveis de 'admission_type_id' para duas categorias\n",
    "    dados['admission_type_id'] = pd.Series(['Emergencia' if val == 1 else 'Outro' \n",
    "                                            for val in dados['admission_type_id']], index = dados.index)\n",
    "\n",
    "\n",
    "    # A variável 'discharge_disposition_id' contém 26 níveis\n",
    "    # Reduziremos os níveis de 'discharge_disposition_id' para duas categorias\n",
    "    dados['discharge_disposition_id'] = pd.Series(['Casa' if val == 1 else 'Outro' \n",
    "                                                  for val in dados['discharge_disposition_id']], index = dados.index)\n",
    "\n",
    "\n",
    "    # A variável 'admission_source_id' contém 17 níveis\n",
    "    # # Reduziremos os níveis de 'admission_source_id' para três categorias\n",
    "    dados['admission_source_id'] = pd.Series(['Sala_Emergencia' if val == 7 else 'Recomendacao' if val == 1 else 'Outro' \n",
    "                                                  for val in dados['admission_source_id']], index = dados.index)\n",
    "\n",
    "\n",
    "    # Concatena 3 variáveis em um dataframe\n",
    "    diagnostico = dados[['diag_1', 'diag_2', 'diag_3']]\n",
    "\n",
    "    # Aplicamos a função comorbidade aos dados\n",
    "    dados['comorbidade'] = diagnostico.apply(calcula_comorbidade, axis = 1)\n",
    "\n",
    "    # Drop das variáveis individuais\n",
    "    dados.drop(['diag_1','diag_2','diag_3'], axis = 1, inplace = True)\n",
    "    \n",
    "    # Removendo dataframe temporario\n",
    "    del diagnostico\n",
    "\n",
    "    # Lista com os nomes das variáveis de medicamentos (3 variáveis já tinham sido removidas)\n",
    "    medicamentos = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', \n",
    "                    'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', \n",
    "                    'troglitazone', 'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin', \n",
    "                    'glimepiride-pioglitazone', 'metformin-pioglitazone']\n",
    "\n",
    "\n",
    "    # Loop para ajustar o valor das variáveis de medicamentos\n",
    "    for col in medicamentos:\n",
    "        if col in dados.columns:\n",
    "            colname = str(col) + 'temp'\n",
    "            dados[colname] = dados[col].apply(lambda x: 0 if (x == 'No' or x == 'Steady') else 1)\n",
    "\n",
    "\n",
    "    # Cria uma variável para receber a contagem por paciente\n",
    "    dados['num_alt_dosagem_med'] = 0\n",
    "\n",
    "    # Contagem de modificações na dosagem de medicamentos\n",
    "    for col in medicamentos:\n",
    "        if col in dados.columns:\n",
    "            colname = str(col) + 'temp'\n",
    "            dados['num_alt_dosagem_med'] = dados['num_alt_dosagem_med'] + dados[colname]\n",
    "            del dados[colname]\n",
    "\n",
    "\n",
    "    # Recoding das colunas de medicamentos\n",
    "    for col in medicamentos:\n",
    "        if col in dados.columns:\n",
    "            dados[col] = dados[col].replace('No', 0)\n",
    "            dados[col] = dados[col].replace('Steady', 1)\n",
    "            dados[col] = dados[col].replace('Up', 1)\n",
    "            dados[col] = dados[col].replace('Down', 1) \n",
    "\n",
    "\n",
    "    # Variável com a contagem de medicamentos por paciente\n",
    "    dados['num_med'] = 0\n",
    "\n",
    "    # Carregamos a nova variável\n",
    "    for col in medicamentos:\n",
    "        if col in dados.columns:\n",
    "            dados['num_med'] = dados['num_med'] + dados[col]\n",
    "\n",
    "\n",
    "    # Remove as colunas de medicamentos\n",
    "    dados = dados.drop(columns = medicamentos)\n",
    "\n",
    "\n",
    "    # Recoding de variáveis categóricas binárias\n",
    "    dados['change'] = dados['change'].replace('Ch', 1)\n",
    "    dados['change'] = dados['change'].replace('No', 0)\n",
    "    dados['gender'] = dados['gender'].replace('Male', 1)\n",
    "    dados['gender'] = dados['gender'].replace('Female', 0)\n",
    "    dados['diabetesMed'] = dados['diabetesMed'].replace('Yes', 1)\n",
    "    dados['diabetesMed'] = dados['diabetesMed'].replace('No', 0)\n",
    "\n",
    "\n",
    "    # Recoding de variáveis categóricas (label encoding)\n",
    "    dados['A1Cresult'] = dados['A1Cresult'].replace('>7', 1)\n",
    "    dados['A1Cresult'] = dados['A1Cresult'].replace('>8', 1)\n",
    "    dados['A1Cresult'] = dados['A1Cresult'].replace('Norm', 0)\n",
    "    dados['A1Cresult'] = dados['A1Cresult'].replace('None', -99)\n",
    "    dados['max_glu_serum'] = dados['max_glu_serum'].replace('>200', 1)\n",
    "    dados['max_glu_serum'] = dados['max_glu_serum'].replace('>300', 1)\n",
    "    dados['max_glu_serum'] = dados['max_glu_serum'].replace('Norm', 0)\n",
    "    dados['max_glu_serum'] = dados['max_glu_serum'].replace('None', -99)\n",
    "\n",
    "\n",
    "    # Removendo duplicidades por id de paciente, mantendo o primeiro registro\n",
    "    dados = dados.drop_duplicates(subset = ['patient_nbr'], keep = 'first')\n",
    "\n",
    "\n",
    "    # Remove as variáveis de ID\n",
    "    dados.drop(['encounter_id', 'patient_nbr'], axis = 1, inplace = True)\n",
    "    \n",
    "    return dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que calcula a Comorbidade\n",
    "def calcula_comorbidade(row):\n",
    "    \n",
    "    # Código 250 indica diabetes\n",
    "    codigos_doenca_diabetes = \"^[2][5][0]\"\n",
    "    \n",
    "    # Códigos 39x (x = valor entre 0 e 9)\n",
    "    # Códigos 4zx (z = valor entre 0 e 6 e x = valor entre 0 e 9)\n",
    "    # Esses códigos indicam problemas circulatórios\n",
    "    codigos_doenca_circulatorios = \"^[3][9][0-9]|^[4][0-5][0-9]\"\n",
    "    \n",
    "    # Inicializa variável de retorno\n",
    "    valor = 0\n",
    "    \n",
    "    # Valor 0 indica que:\n",
    "    # Diabetes E problemas circulatórios não foram detectados de forma simultânea no paciente\n",
    "    if(not(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_1']))))) and\n",
    "       not(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_2']))))) and \n",
    "       not(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_3'])))))) and (not(\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_1']))))) and not(\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_2']))))) and not(\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_3'])))))):\n",
    "        valor = 0\n",
    "        \n",
    "    # Valor 1 indica que:\n",
    "    # Pelo menos um diagnóstico de diabetes E problemas circulatórios foram detectados de forma \n",
    "    # simultânea no paciente\n",
    "    if(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_1'])))) or \n",
    "       bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_2'])))) or \n",
    "       bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_3']))))) and (not(\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_1']))))) and not(\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_2']))))) and not(\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_3'])))))): \n",
    "        valor = 1\n",
    "        \n",
    "    # Valor 2 indica que:\n",
    "    # Diabetes E pelo menos um diagnóstico de problemas circulatórios foram detectados de forma \n",
    "    # simultânea no paciente\n",
    "    if(not(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_1']))))) and\n",
    "       not(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_2']))))) and \n",
    "       not(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_3'])))))) and (\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_1'])))) or \n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_2'])))) or \n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_3']))))):\n",
    "        valor = 2\n",
    "        \n",
    "    # Valor 3 indica que:\n",
    "    # Pelo menos um diagnóstico de diabetes e pelo menos um diagnóstico de problemas circulatórios \n",
    "    # foram detectados de forma simultânea no paciente\n",
    "    if(bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_1'])))) or \n",
    "       bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_2'])))) or \n",
    "       bool(re.match(codigos_doenca_diabetes, str(np.array(row['diag_3']))))) and (\n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_1'])))) or \n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_2'])))) or \n",
    "        bool(re.match(codigos_doenca_circulatorios, str(np.array(row['diag_3']))))):\n",
    "        valor = 3 \n",
    "    \n",
    "    return valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os dados para treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para balanceamento entre as classes\n",
    "def balanceamento_classe(X, y):\n",
    "\n",
    "    # Extraímos os nomes das colunas das variáveis preditoras\n",
    "    col = df.columns\n",
    "\n",
    "    # Criamos o objeto SMOTE\n",
    "    sm = SMOTE(random_state = 42)\n",
    "\n",
    "    # Treinamos o balanceador SMOTE\n",
    "    new_X, new_y = sm.fit_sample(X, y)   \n",
    "    \n",
    "    return new_X, new_y, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando engenharia de atributos no dataset\n",
    "train = feature_engineering(df)\n",
    "\n",
    "# Vamos armazenar 'readmitted' no rótulo (y) e o restante das colunas em X\n",
    "y = train['readmitted']\n",
    "X = train.drop(['readmitted'], axis = 1)\n",
    "\n",
    "# Vamos criar variáveis dummy para variáveis categóricas\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Cria o padronizador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Padronizando os dados\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Aplicar o balanceamento de classes usando SMOTE\n",
    "new_X, new_y, features_columns = balanceamento_classe(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executando vários modelos de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os valores para o número de folds\n",
    "num_folds = 10\n",
    "seed = 42\n",
    "\n",
    "# Preparando a lista de modelos\n",
    "modelos = []\n",
    "modelos.append(('LR',  LogisticRegression()))\n",
    "modelos.append(('RF',  RandomForestClassifier()))\n",
    "modelos.append(('KNN', KNeighborsClassifier()))\n",
    "modelos.append(('DT',  DecisionTreeClassifier()))\n",
    "modelos.append(('NB',  GaussianNB()))\n",
    "modelos.append(('XGB', XGBClassifier()))\n",
    "modelos.append(('LGB', lgb.LGBMClassifier()))\n",
    "\n",
    "# Avaliando cada modelo em um loop\n",
    "resultados = []\n",
    "nomes      = []\n",
    "\n",
    "for nome, modelo in modelos:\n",
    "    kfold = KFold(n_splits = num_folds, shuffle=True, random_state = seed)\n",
    "    cv_results = cross_val_score(modelo, X, y, cv = kfold, scoring = 'accuracy')\n",
    "    resultados.append(cv_results)\n",
    "    nomes.append(nome)\n",
    "    msg = \"%s: %f (%f)\" % (nome, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot para comparar os algoritmos\n",
    "fig = plt.figure(figsize = (18, 6))\n",
    "\n",
    "fig.suptitle('Comparação do desempenho dos Algoritmos de Classificação')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(resultados)\n",
    "ax.set_xticklabels(nomes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando Otimização de Hyperparametros no melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_distribution(y_true, y_pred, ax):\n",
    "    df = pd.DataFrame({'prediction': y_pred, 'original': y_true})    \n",
    "    sns.distplot(df[df['original'] == 0]['prediction'], label='negative', ax=ax)\n",
    "    sns.distplot(df[df['original'] == 1]['prediction'], label='positive', ax=ax)\n",
    "    ax.legend(prop={'size': 16}, title = 'Labels')\n",
    "    \n",
    "# Definindo os valores para o número de folds\n",
    "N_SPLITS  = 3\n",
    "SEED      = 0\n",
    "\n",
    "TRAIN_PARAMS = {\n",
    "                'num_boosting_rounds': 1000000,\n",
    "                'early_stopping_rounds' : 4000\n",
    "               }\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "                 'boosting_type'           : 'gbdt',\n",
    "                 'metric'                  : 'auc',\n",
    "                 'objective'               : 'binary',\n",
    "                 'learning_rate'           : 0.01,\n",
    "                 'max_depth'               : -1,\n",
    "                 'min_data_in_leaf'        : 260,\n",
    "                 'min_sum_hessian_in_leaf' : 10.0,\n",
    "                 'num_leaves'              : 10,\n",
    "                 'verbosity'               : 1\n",
    "               }\n",
    "\n",
    "folds = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "oof = np.zeros(len(new_X))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(new_X, new_y)):\n",
    "\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "\n",
    "    trn_data = lgb.Dataset(new_X[trn_idx], label=new_y[trn_idx])\n",
    "    val_data = lgb.Dataset(new_X[val_idx], label=new_y[val_idx])\n",
    "\n",
    "    clf = lgb.train(MODEL_PARAMS, \n",
    "                    trn_data, \n",
    "                    TRAIN_PARAMS['num_boosting_rounds'], \n",
    "                    valid_sets = [trn_data, val_data], \n",
    "                    verbose_eval = 5000, \n",
    "                    early_stopping_rounds = TRAIN_PARAMS['early_stopping_rounds'])\n",
    "\n",
    "    oof[val_idx] = clf.predict(new_X[val_idx], num_iteration=clf.best_iteration)            \n",
    "    \n",
    "roc_auc_oof = roc_auc_score(new_y, oof)\n",
    "print(\"CV ROC_AUC score: {:<8.5f}\".format(roc_auc_oof))\n",
    "\n",
    "preds = pd.DataFrame(oof, columns=['pos_preds'])\n",
    "preds['neg_preds'] = 1.0 - preds['pos_preds']\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(24, 6))\n",
    "\n",
    "plot_prediction_distribution(new_y, preds['pos_preds'], ax=ax1);\n",
    "\n",
    "plot_roc(new_y, preds[['neg_preds','pos_preds']], ax=ax2);\n",
    "\n",
    "plot_confusion_matrix(new_y, oof > 0.5, ax=ax3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização do Desempenho do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_oof = roc_auc_score(new_y, oof)\n",
    "print(\"CV ROC_AUC score: {:<8.5f}\".format(roc_auc_oof))\n",
    "\n",
    "preds = pd.DataFrame(oof, columns=['pos_preds'])\n",
    "preds['neg_preds'] = 1.0 - preds['pos_preds']\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(24, 6))\n",
    "\n",
    "plot_prediction_distribution(new_y, preds['pos_preds'], ax=ax1);\n",
    "\n",
    "plot_roc(new_y, preds[['neg_preds','pos_preds']], ax=ax2);\n",
    "\n",
    "plot_confusion_matrix(new_y, oof > 0.5, ax=ax3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estratificação de Risco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para estratificar o risco\n",
    "def classifica_risco(row):\n",
    "    if row[0] <= 0.3 : return 'Baixo'\n",
    "    if row[0] >= 0.7 : return 'Alto'\n",
    "    return 'Médio'\n",
    "\n",
    "# Criando um novo dataset com as previsões\n",
    "df_proba = pd.DataFrame(oof, columns = ['Probabilidade'])\n",
    "\n",
    "# Dataframe para o risco estratificado\n",
    "df_risco = pd.DataFrame()\n",
    "\n",
    "# Agora carregamos o dataframe\n",
    "df_risco['Risco'] = df_proba.apply(classifica_risco, axis = 1)\n",
    "\n",
    "# Vamos separar em percentual\n",
    "percentual = round(df_risco.Risco.value_counts() / len(df_risco.index) * 100, 1)\n",
    "\n",
    "# Legenda para o gráfico\n",
    "sub = ['Médio', 'Alto', 'Baixo']\n",
    "\n",
    "# Plot\n",
    "plt.axis(\"equal\")\n",
    "plt.pie(percentual , \n",
    "        labels = sub, \n",
    "        radius = 1.6,\n",
    "        autopct = '%1.2f%%',\n",
    "        explode = [0.09,0.09,0.09],\n",
    "        startangle = 30,\n",
    "        shadow = True,\n",
    "        counterclock = False,\n",
    "        pctdistance = 0.8)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
